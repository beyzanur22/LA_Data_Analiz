{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MODEL 2: Chi-Square + Logistic Regression\n",
        "\n",
        "**Hazırlayan:** İsmail Can Günay\n",
        "\n",
        "## Model Özeti\n",
        "- **Feature Selection:** Chi-Square Test (100 özellik)\n",
        "- **Model:** Logistic Regression (L2 regularization)\n",
        "- **Hedef:** Part 1-2 (Binary Classification)\n",
        "\n",
        "## Veri Kullanımı\n",
        "- **Toplam Train Verisi:** 848,024 örnek\n",
        "- **Sampling (Feature Selection için):** 150,000 örnek (stratified)\n",
        "- **Model Eğitimi:** Tüm train verisi (848,024 örnek) - Seçilen 100 özellik ile\n",
        "- **Test Verisi:** 147,207 örnek\n",
        "- **Toplam Özellik:** 1,786 (encoding sonrası)\n",
        "- **Seçilen Özellik:** 100\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Gerekli kütüphaneleri yükle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.sparse import load_npz, csr_matrix\n",
        "from sklearn.feature_selection import chi2, SelectKBest\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import joblib\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"MODEL 2: Chi-Square + Logistic Regression\")\n",
        "print(\"Hazirlayan: Ismail Can Gunay\")\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Temizlenmiş dataset'i yükle (tek dosya)\n",
        "df_clean = pd.read_csv(\"clean_data.csv\")\n",
        "\n",
        "# Sparse matrisi yükle (tüm özellikler)\n",
        "X_clean_full = load_npz(\"X_clean_ready.npz\")\n",
        "\n",
        "# Target değişkeni\n",
        "y_clean = df_clean['Part 1-2'].copy()\n",
        "y_clean_binary = (y_clean > 0).astype(int)  # 0: Part 1, 1: Part 2\n",
        "\n",
        "print(f\"Clean data boyutu: {X_clean_full.shape}\")\n",
        "print(f\"Target dağılımı: {pd.Series(y_clean_binary).value_counts().to_dict()}\")\n",
        "\n",
        "# Clean data'dan train ve test setlerini ayır (stratified split)\n",
        "print(\"\\nClean data'dan train ve test setleri ayrılıyor (stratified split)...\")\n",
        "train_indices, test_indices = train_test_split(\n",
        "    df_clean.index,\n",
        "    test_size=0.2,  # %20 test, %80 train\n",
        "    stratify=y_clean_binary,\n",
        "    random_state=123  # Model 2 için özel random seed (Model 1'den farklı)\n",
        ")\n",
        "\n",
        "# Sparse matrisi ve target'ı bu indekslere göre böl\n",
        "X_train_full = X_clean_full[train_indices]\n",
        "X_test_full = X_clean_full[test_indices]\n",
        "y_train_binary = y_clean_binary.iloc[train_indices].values\n",
        "y_test_binary = y_clean_binary.iloc[test_indices].values\n",
        "\n",
        "# DataFrame'i de aynı indekslere göre böl\n",
        "df_train = df_clean.loc[train_indices].reset_index(drop=True)\n",
        "df_test = df_clean.loc[test_indices].reset_index(drop=True)\n",
        "\n",
        "print(f\"Train set boyutu: {X_train_full.shape}\")\n",
        "print(f\"Test set boyutu: {X_test_full.shape}\")\n",
        "print(f\"Train target dağılımı: {pd.Series(y_train_binary).value_counts().to_dict()}\")\n",
        "\n",
        "# Stratified sampling (farklı bir örnekleme stratejisi)\n",
        "print(\"\\nStratified sampling yapılıyor (150,000 örnek)...\")\n",
        "X_sample, _, y_sample, _ = train_test_split(\n",
        "    X_train_full, \n",
        "    y_train_binary,\n",
        "    train_size=150000,\n",
        "    stratify=y_train_binary,\n",
        "    random_state=123  # Farklı random seed (Model 1'den farklı)\n",
        ")\n",
        "print(f\"Sampling sonrası: {X_sample.shape}\")\n",
        "\n",
        "print(f\"\\nVERİ KULLANIMI ÖZETİ:\")\n",
        "print(f\"  - Toplam train verisi: {X_train_full.shape[0]:,} örnek\")\n",
        "print(f\"  - Sampling (feature selection için): {X_sample.shape[0]:,} örnek\")\n",
        "print(f\"  - Model eğitimi: {X_train_full.shape[0]:,} örnek (tüm train verisi)\")\n",
        "print(f\"  - Test verisi: {X_test_full.shape[0]:,} örnek\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## AŞAMA 2: NORMALIZASYON VE CHI-SQUARE FEATURE SELECTION\n",
        "\n",
        "**Veri Kullanımı:**\n",
        "- **Normalizasyon:** 150,000 örnek (MinMaxScaler için)\n",
        "- **Feature Selection:** 150,000 örnek üzerinde çalışıyor\n",
        "- **Seçilen özellik sayısı:** 100\n",
        "- **Tüm train/test setlerine uygulanıyor:** 848,024 train / 147,207 test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Chi-Square için non-negative değerler gerekli (MinMax scaling)\n",
        "print(\"\\nChi-Square için veriler normalize ediliyor (0-1 arası)...\")\n",
        "scaler = MinMaxScaler()\n",
        "X_sample_dense = X_sample.toarray()\n",
        "X_sample_scaled = scaler.fit_transform(X_sample_dense)\n",
        "X_sample_scaled = csr_matrix(X_sample_scaled)  # Tekrar sparse'a çevir\n",
        "\n",
        "# Chi-Square: Kategorik özelliklerin target ile istatistiksel bağımsızlığını test eder\n",
        "print(\"\\nChi-Square testi ile feature selection yapılıyor...\")\n",
        "print(\"Chi-Square skorları hesaplanıyor (bu biraz zaman alabilir)...\")\n",
        "\n",
        "# En iyi 100 özelliği seç\n",
        "k_best = 100\n",
        "chi2_selector = SelectKBest(score_func=chi2, k=k_best)\n",
        "X_selected = chi2_selector.fit_transform(X_sample_scaled, y_sample)\n",
        "\n",
        "# Seçilen özelliklerin indekslerini al\n",
        "selected_indices = chi2_selector.get_support(indices=True)\n",
        "\n",
        "# Tüm train ve test setlerine uygula (önce normalize et)\n",
        "print(\"\\nTüm veri setine normalize ve feature selection uygulanıyor...\")\n",
        "X_train_dense = X_train_full.toarray()\n",
        "X_test_dense = X_test_full.toarray()\n",
        "\n",
        "X_train_scaled = scaler.transform(X_train_dense)\n",
        "X_test_scaled = scaler.transform(X_test_dense)\n",
        "\n",
        "X_train_selected = csr_matrix(X_train_scaled[:, selected_indices])\n",
        "X_test_selected = csr_matrix(X_test_scaled[:, selected_indices])\n",
        "\n",
        "print(f\"Seçilen özellik sayısı: {len(selected_indices)}\")\n",
        "print(f\"Seçilen özelliklerin ilk 10 indeksi: {selected_indices[:10]}\")\n",
        "\n",
        "# Chi-Square skorlarını göster\n",
        "chi2_scores = chi2_selector.scores_\n",
        "valid_scores = chi2_scores[~np.isnan(chi2_scores)]\n",
        "if len(valid_scores) > 0:\n",
        "    top_10_indices = np.argsort(valid_scores)[-10:][::-1]\n",
        "    print(f\"\\nEn yüksek Chi-Square skorlarına sahip 10 özellik:\")\n",
        "    for idx in top_10_indices[:10]:\n",
        "        if not np.isnan(chi2_scores[idx]):\n",
        "            print(f\"  Özellik {idx}: Chi2 = {chi2_scores[idx]:.2f}\")\n",
        "\n",
        "print(f\"\\nVERİ KULLANIMI:\")\n",
        "print(f\"  - Normalizasyon: {X_sample.shape[0]:,} örnek kullanıldı\")\n",
        "print(f\"  - Feature selection: {X_sample.shape[0]:,} örnek kullanıldı\")\n",
        "print(f\"  - Seçilen özellik sayısı: {len(selected_indices)}\")\n",
        "print(f\"  - Train set (seçilen özelliklerle): {X_train_selected.shape}\")\n",
        "print(f\"  - Test set (seçilen özelliklerle): {X_test_selected.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## AŞAMA 3: LOGISTIC REGRESSION MODEL EĞİTİMİ\n",
        "\n",
        "**Veri Kullanımı:**\n",
        "- **Model Eğitimi:** Tüm train verisi (848,024 örnek) - 100 seçilen özellik ile\n",
        "- **Model:** Logistic Regression (L2 regularization)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Logistic Regression: Doğrusal bir sınıflandırma modeli\n",
        "lr_model = LogisticRegression(\n",
        "    C=1.0,                    # Regularization parametresi\n",
        "    penalty='l2',             # L2 regularization (Ridge)\n",
        "    solver='lbfgs',           # Optimizasyon algoritması\n",
        "    max_iter=1000,           # Maksimum iterasyon\n",
        "    random_state=42,\n",
        "    class_weight='balanced',  # Dengesiz sınıflar için ağırlıklandırma\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "print(\"Model eğitimi başlıyor...\")\n",
        "print(f\"Eğitim verisi: {X_train_selected.shape[0]:,} örnek, {X_train_selected.shape[1]} özellik\")\n",
        "lr_model.fit(X_train_selected, y_train_binary)\n",
        "print(\"Model eğitimi tamamlandı!\")\n",
        "\n",
        "# Katsayıları göster\n",
        "coefficients = lr_model.coef_[0]\n",
        "top_10_features = np.argsort(np.abs(coefficients))[-10:][::-1]\n",
        "print(f\"\\nEn yüksek katsayıya sahip 10 özellik:\")\n",
        "for i, idx in enumerate(top_10_features):\n",
        "    feat_idx = selected_indices[idx]\n",
        "    print(f\"  {i+1}. Özellik {feat_idx}: Coef = {coefficients[idx]:.4f}\")\n",
        "\n",
        "print(f\"\\nVERİ KULLANIMI:\")\n",
        "print(f\"  - Model eğitimi: {X_train_selected.shape[0]:,} örnek kullanıldı\")\n",
        "print(f\"  - Özellik sayısı: {X_train_selected.shape[1]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## AŞAMA 4: TEST SETİNE TAHMİN\n",
        "\n",
        "**Veri Kullanımı:**\n",
        "- **Test Tahminleri:** 147,207 örnek\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test setine tahmin\n",
        "y_pred_proba = lr_model.predict_proba(X_test_selected)[:, 1]  # Part 2 olasılığı\n",
        "y_pred = lr_model.predict(X_test_selected)\n",
        "\n",
        "print(f\"Tahmin edilen sınıf dağılımı:\")\n",
        "print(f\"  Part 1 (0): {(y_pred == 0).sum()}\")\n",
        "print(f\"  Part 2 (1): {(y_pred == 1).sum()}\")\n",
        "\n",
        "print(f\"\\nVERİ KULLANIMI:\")\n",
        "print(f\"  - Test tahminleri: {X_test_selected.shape[0]:,} örnek\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## AŞAMA 5: SUBMISSION DOSYASI OLUŞTURMA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test setindeki DR_NO'ları al\n",
        "submission_df = pd.DataFrame({\n",
        "    'DR_NO': df_test['DR_NO'].values if 'DR_NO' in df_test.columns else df_test.index.values,\n",
        "    'Part 1-2': y_pred\n",
        "})\n",
        "\n",
        "# Orijinal değerlere geri çevir\n",
        "submission_df['Part 1-2'] = submission_df['Part 1-2'].map({\n",
        "    0: -0.834220,\n",
        "    1: 1.198725\n",
        "})\n",
        "\n",
        "# Dosyayı kaydet\n",
        "submission_file = \"ismailcan_model2_submission.csv\"\n",
        "submission_df.to_csv(submission_file, index=False)\n",
        "print(f\"[OK] Submission dosyasi kaydedildi: {submission_file}\")\n",
        "print(f\"   Toplam tahmin sayısı: {len(submission_df)}\")\n",
        "\n",
        "# Model ve selector'ı kaydet\n",
        "joblib.dump(lr_model, \"ismailcan_model2_lr.pkl\")\n",
        "joblib.dump(chi2_selector, \"ismailcan_model2_selector.pkl\")\n",
        "joblib.dump(selected_indices, \"ismailcan_model2_selected_indices.pkl\")\n",
        "joblib.dump(scaler, \"ismailcan_model2_scaler.pkl\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"MODEL 2 TAMAMLANDI!\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nÖZET:\")\n",
        "print(f\"  - Feature Selection: Chi-Square Test (Top {k_best} features)\")\n",
        "print(f\"  - Model: Logistic Regression (L2 regularization)\")\n",
        "print(f\"  - Submission: {submission_file}\")\n",
        "print(\"\\nVERİ KULLANIMI ÖZETİ:\")\n",
        "print(f\"  - Toplam train verisi: {X_train_full.shape[0]:,} örnek\")\n",
        "print(f\"  - Sampling (feature selection): {X_sample.shape[0]:,} örnek\")\n",
        "print(f\"  - Model eğitimi: {X_train_selected.shape[0]:,} örnek\")\n",
        "print(f\"  - Test tahminleri: {X_test_selected.shape[0]:,} örnek\")\n",
        "print(\"=\"*70)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
