{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Gerekli kütüphaneleri yükle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.sparse import load_npz, csr_matrix\n",
        "from sklearn.feature_selection import mutual_info_classif, SelectKBest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "import joblib\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"MODEL 1: Mutual Information + Random Forest\")\n",
        "print(\"Hazirlayan: Ismail Can Gunay\")\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Temizlenmiş dataset'i yükle (tek dosya)\n",
        "df_clean = pd.read_csv(\"clean_data.csv\")\n",
        "\n",
        "# Sparse matrisi yükle (tüm özellikler)\n",
        "X_clean_full = load_npz(\"X_clean_ready.npz\")\n",
        "\n",
        "# Target değişkeni\n",
        "y_clean = df_clean['Part 1-2'].copy()\n",
        "y_clean_binary = (y_clean > 0).astype(int)  # 0: Part 1, 1: Part 2\n",
        "\n",
        "print(f\"Clean data boyutu: {X_clean_full.shape}\")\n",
        "print(f\"Target dağılımı: {pd.Series(y_clean_binary).value_counts().to_dict()}\")\n",
        "\n",
        "# Clean data'dan train ve test setlerini ayır (stratified split)\n",
        "print(\"\\nClean data'dan train ve test setleri ayrılıyor (stratified split)...\")\n",
        "train_indices, test_indices = train_test_split(\n",
        "    df_clean.index,\n",
        "    test_size=0.2,  # %20 test, %80 train\n",
        "    stratify=y_clean_binary,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Sparse matrisi ve target'ı bu indekslere göre böl\n",
        "X_train_full = X_clean_full[train_indices]\n",
        "X_test_full = X_clean_full[test_indices]\n",
        "y_train_binary = y_clean_binary.iloc[train_indices].values\n",
        "y_test_binary = y_clean_binary.iloc[test_indices].values\n",
        "\n",
        "# DataFrame'i de aynı indekslere göre böl\n",
        "df_train = df_clean.loc[train_indices].reset_index(drop=True)\n",
        "df_test = df_clean.loc[test_indices].reset_index(drop=True)\n",
        "\n",
        "print(f\"Train set boyutu: {X_train_full.shape}\")\n",
        "print(f\"Test set boyutu: {X_test_full.shape}\")\n",
        "print(f\"Train target dağılımı: {pd.Series(y_train_binary).value_counts().to_dict()}\")\n",
        "\n",
        "# Stratified sampling (veri çok büyük, hız için örnekleme)\n",
        "print(\"\\nStratified sampling yapılıyor (200,000 örnek)...\")\n",
        "X_sample, _, y_sample, _ = train_test_split(\n",
        "    X_train_full, \n",
        "    y_train_binary,\n",
        "    train_size=200000,\n",
        "    stratify=y_train_binary,\n",
        "    random_state=42\n",
        ")\n",
        "print(f\"Sampling sonrası: {X_sample.shape}\")\n",
        "print(f\"\\nVERİ KULLANIMI ÖZETİ:\")\n",
        "print(f\"  - Toplam train verisi: {X_train_full.shape[0]:,} örnek\")\n",
        "print(f\"  - Sampling (feature selection için): {X_sample.shape[0]:,} örnek\")\n",
        "print(f\"  - Model eğitimi: {X_train_full.shape[0]:,} örnek (tüm train verisi)\")\n",
        "print(f\"  - Test verisi: {X_test_full.shape[0]:,} örnek\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## AŞAMA 2: MUTUAL INFORMATION FEATURE SELECTION\n",
        "\n",
        "**Veri Kullanımı:**\n",
        "- **Feature Selection:** 200,000 örnek üzerinde çalışıyor\n",
        "- **Seçilen özellik sayısı:** 150\n",
        "- **Tüm train/test setlerine uygulanıyor:** 848,024 train / 147,207 test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mutual Information: Her özelliğin target ile bilgi paylaşımını ölçer\n",
        "# Yüksek MI = Özellik target'ı tahmin etmede daha bilgilendirici\n",
        "print(\"Mutual Information skorları hesaplanıyor (bu biraz zaman alabilir)...\")\n",
        "\n",
        "# En iyi 150 özelliği seç\n",
        "k_best = 150\n",
        "mi_selector = SelectKBest(score_func=mutual_info_classif, k=k_best)\n",
        "X_selected = mi_selector.fit_transform(X_sample, y_sample)\n",
        "\n",
        "# Seçilen özelliklerin indekslerini al\n",
        "selected_indices = mi_selector.get_support(indices=True)\n",
        "\n",
        "# Tüm train ve test setlerine uygula\n",
        "X_train_selected = X_train_full[:, selected_indices]\n",
        "X_test_selected = X_test_full[:, selected_indices]\n",
        "\n",
        "print(f\"Seçilen özellik sayısı: {len(selected_indices)}\")\n",
        "print(f\"Seçilen özelliklerin ilk 10 indeksi: {selected_indices[:10]}\")\n",
        "\n",
        "# MI skorlarını göster\n",
        "mi_scores = mi_selector.scores_\n",
        "top_10_indices = np.argsort(mi_scores)[-10:][::-1]\n",
        "print(f\"\\nEn yüksek MI skorlarına sahip 10 özellik:\")\n",
        "for idx in top_10_indices:\n",
        "    print(f\"  Özellik {idx}: MI = {mi_scores[idx]:.4f}\")\n",
        "\n",
        "print(f\"\\nVERİ KULLANIMI:\")\n",
        "print(f\"  - Feature selection: {X_sample.shape[0]:,} örnek kullanıldı\")\n",
        "print(f\"  - Seçilen özellik sayısı: {len(selected_indices)}\")\n",
        "print(f\"  - Train set (seçilen özelliklerle): {X_train_selected.shape}\")\n",
        "print(f\"  - Test set (seçilen özelliklerle): {X_test_selected.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## AŞAMA 3: RANDOM FOREST MODEL EĞİTİMİ\n",
        "\n",
        "**Veri Kullanımı:**\n",
        "- **Model Eğitimi:** Tüm train verisi (848,024 örnek) - 150 seçilen özellik ile\n",
        "- **Model:** Random Forest (200 ağaç)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Random Forest: Birden fazla karar ağacının birleşimi\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=200,        # 200 ağaç\n",
        "    max_depth=20,            # Ağaç derinliği (overfitting'i önlemek için)\n",
        "    min_samples_split=50,    # Split için minimum örnek sayısı\n",
        "    min_samples_leaf=20,     # Leaf için minimum örnek sayısı\n",
        "    random_state=42,\n",
        "    n_jobs=-1,               # Tüm CPU'ları kullan\n",
        "    class_weight='balanced'  # Dengesiz sınıflar için ağırlıklandırma\n",
        ")\n",
        "\n",
        "print(\"Model eğitimi başlıyor...\")\n",
        "print(f\"Eğitim verisi: {X_train_selected.shape[0]:,} örnek, {X_train_selected.shape[1]} özellik\")\n",
        "rf_model.fit(X_train_selected, y_train_binary)\n",
        "print(\"Model eğitimi tamamlandı!\")\n",
        "\n",
        "# Feature importance göster\n",
        "feature_importance = rf_model.feature_importances_\n",
        "top_10_features = np.argsort(feature_importance)[-10:][::-1]\n",
        "print(f\"\\nEn önemli 10 özellik (Random Forest'e göre):\")\n",
        "for i, idx in enumerate(top_10_features):\n",
        "    feat_idx = selected_indices[idx]\n",
        "    print(f\"  {i+1}. Özellik {feat_idx}: Importance = {feature_importance[idx]:.4f}\")\n",
        "\n",
        "print(f\"\\nVERİ KULLANIMI:\")\n",
        "print(f\"  - Model eğitimi: {X_train_selected.shape[0]:,} örnek kullanıldı\")\n",
        "print(f\"  - Özellik sayısı: {X_train_selected.shape[1]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## AŞAMA 4: TEST SETİNE TAHMİN\n",
        "\n",
        "**Veri Kullanımı:**\n",
        "- **Test Tahminleri:** 147,207 örnek\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test setine tahmin\n",
        "y_pred_proba = rf_model.predict_proba(X_test_selected)[:, 1]  # Part 2 olasılığı\n",
        "y_pred = rf_model.predict(X_test_selected)\n",
        "\n",
        "print(f\"Tahmin edilen sınıf dağılımı:\")\n",
        "print(f\"  Part 1 (0): {(y_pred == 0).sum()}\")\n",
        "print(f\"  Part 2 (1): {(y_pred == 1).sum()}\")\n",
        "\n",
        "print(f\"\\nVERİ KULLANIMI:\")\n",
        "print(f\"  - Test tahminleri: {X_test_selected.shape[0]:,} örnek\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## AŞAMA 5: SUBMISSION DOSYASI OLUŞTURMA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test setindeki DR_NO'ları al\n",
        "submission_df = pd.DataFrame({\n",
        "    'DR_NO': df_test['DR_NO'].values if 'DR_NO' in df_test.columns else df_test.index.values,\n",
        "    'Part 1-2': y_pred\n",
        "})\n",
        "\n",
        "# Orijinal değerlere geri çevir\n",
        "submission_df['Part 1-2'] = submission_df['Part 1-2'].map({\n",
        "    0: -0.834220,\n",
        "    1: 1.198725\n",
        "})\n",
        "\n",
        "# Dosyayı kaydet\n",
        "submission_file = \"ismailcan_model1_submission.csv\"\n",
        "submission_df.to_csv(submission_file, index=False)\n",
        "print(f\"[OK] Submission dosyasi kaydedildi: {submission_file}\")\n",
        "print(f\"   Toplam tahmin sayısı: {len(submission_df)}\")\n",
        "\n",
        "# Model ve selector'ı kaydet\n",
        "joblib.dump(rf_model, \"ismailcan_model1_rf.pkl\")\n",
        "joblib.dump(mi_selector, \"ismailcan_model1_selector.pkl\")\n",
        "joblib.dump(selected_indices, \"ismailcan_model1_selected_indices.pkl\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"MODEL 1 TAMAMLANDI!\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nÖZET:\")\n",
        "print(f\"  - Feature Selection: Mutual Information (Top {k_best} features)\")\n",
        "print(f\"  - Model: Random Forest (200 trees)\")\n",
        "print(f\"  - Submission: {submission_file}\")\n",
        "print(\"\\nVERİ KULLANIMI ÖZETİ:\")\n",
        "print(f\"  - Toplam train verisi: {X_train_full.shape[0]:,} örnek\")\n",
        "print(f\"  - Sampling (feature selection): {X_sample.shape[0]:,} örnek\")\n",
        "print(f\"  - Model eğitimi: {X_train_selected.shape[0]:,} örnek\")\n",
        "print(f\"  - Test tahminleri: {X_test_selected.shape[0]:,} örnek\")\n",
        "print(\"=\"*70)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
