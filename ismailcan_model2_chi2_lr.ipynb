{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL 2: Chi-Square + Logistic Regression\n",
    "\n",
    "**Hazırlayan:** İsmail Can Günay\n",
    "\n",
    "## Model Özeti\n",
    "- **Feature Selection:** Chi-Square Test (100 özellik)\n",
    "- **Model:** Logistic Regression (L2 regularization)\n",
    "- **Hedef:** Part 1-2 (Binary Classification)\n",
    "\n",
    "## Veri Kullanımı\n",
    "- **Toplam Train Verisi:** 848,024 örnek\n",
    "- **Sampling (Feature Selection için):** 150,000 örnek (stratified)\n",
    "- **Model Eğitimi:** Tüm train verisi (848,024 örnek) - Seçilen 100 özellik ile\n",
    "- **Test Verisi:** 147,207 örnek\n",
    "- **Toplam Özellik:** 1,786 (encoding sonrası)\n",
    "- **Seçilen Özellik:** 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "MODEL 2: Chi-Square + Logistic Regression\n",
      "Hazirlayan: Ismail Can Gunay\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Gerekli kütüphaneleri yükle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import load_npz, csr_matrix\n",
    "from sklearn.feature_selection import chi2, SelectKBest\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"MODEL 2: Chi-Square + Logistic Regression\")\n",
    "print(\"Hazirlayan: Ismail Can Gunay\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean data boyutu: (995231, 1786)\n",
      "Target dağılımı: {0: 600045, 1: 395186}\n",
      "\n",
      "Clean data'dan train ve test setleri ayrılıyor (stratified split)...\n",
      "Train set boyutu: (796184, 1786)\n",
      "Test set boyutu: (199047, 1786)\n",
      "Train target dağılımı: {0: 480036, 1: 316148}\n",
      "\n",
      "Stratified sampling yapılıyor (150,000 örnek)...\n",
      "Sampling sonrası: (150000, 1786)\n",
      "\n",
      "VERİ KULLANIMI ÖZETİ:\n",
      "  - Toplam train verisi: 796,184 örnek\n",
      "  - Sampling (feature selection için): 150,000 örnek\n",
      "  - Model eğitimi: 796,184 örnek (tüm train verisi)\n",
      "  - Test verisi: 199,047 örnek\n"
     ]
    }
   ],
   "source": [
    "# Temizlenmiş dataset'i yükle (tek dosya)\n",
    "df_clean = pd.read_csv(\"C:\\AzraTanriver\\CrimeData\\ismailcan_gunay_modeller\\clean_data.csv\")\n",
    "\n",
    "# Sparse matrisi yükle (tüm özellikler)\n",
    "X_clean_full = load_npz(\"X_clean_ready.npz\")\n",
    "\n",
    "# Target değişkeni\n",
    "y_clean = df_clean['Part 1-2'].copy()\n",
    "y_clean_binary = (y_clean > 0).astype(int)  # 0: Part 1, 1: Part 2\n",
    "\n",
    "print(f\"Clean data boyutu: {X_clean_full.shape}\")\n",
    "print(f\"Target dağılımı: {pd.Series(y_clean_binary).value_counts().to_dict()}\")\n",
    "\n",
    "# Clean data'dan train ve test setlerini ayır (stratified split)\n",
    "print(\"\\nClean data'dan train ve test setleri ayrılıyor (stratified split)...\")\n",
    "train_indices, test_indices = train_test_split(\n",
    "    df_clean.index,\n",
    "    test_size=0.2,  # %20 test, %80 train\n",
    "    stratify=y_clean_binary,\n",
    "    random_state=123  # Model 2 için özel random seed (Model 1'den farklı)\n",
    ")\n",
    "\n",
    "# Sparse matrisi ve target'ı bu indekslere göre böl\n",
    "X_train_full = X_clean_full[train_indices]\n",
    "X_test_full = X_clean_full[test_indices]\n",
    "y_train_binary = y_clean_binary.iloc[train_indices].values\n",
    "y_test_binary = y_clean_binary.iloc[test_indices].values\n",
    "\n",
    "# DataFrame'i de aynı indekslere göre böl\n",
    "df_train = df_clean.loc[train_indices].reset_index(drop=True)\n",
    "df_test = df_clean.loc[test_indices].reset_index(drop=True)\n",
    "\n",
    "print(f\"Train set boyutu: {X_train_full.shape}\")\n",
    "print(f\"Test set boyutu: {X_test_full.shape}\")\n",
    "print(f\"Train target dağılımı: {pd.Series(y_train_binary).value_counts().to_dict()}\")\n",
    "\n",
    "# Stratified sampling (farklı bir örnekleme stratejisi)\n",
    "print(\"\\nStratified sampling yapılıyor (150,000 örnek)...\")\n",
    "X_sample, _, y_sample, _ = train_test_split(\n",
    "    X_train_full, \n",
    "    y_train_binary,\n",
    "    train_size=150000,\n",
    "    stratify=y_train_binary,\n",
    "    random_state=123  # Farklı random seed (Model 1'den farklı)\n",
    ")\n",
    "print(f\"Sampling sonrası: {X_sample.shape}\")\n",
    "\n",
    "print(f\"\\nVERİ KULLANIMI ÖZETİ:\")\n",
    "print(f\"  - Toplam train verisi: {X_train_full.shape[0]:,} örnek\")\n",
    "print(f\"  - Sampling (feature selection için): {X_sample.shape[0]:,} örnek\")\n",
    "print(f\"  - Model eğitimi: {X_train_full.shape[0]:,} örnek (tüm train verisi)\")\n",
    "print(f\"  - Test verisi: {X_test_full.shape[0]:,} örnek\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chi-Square için veriler normalize ediliyor (0-1 arası)...\n",
      "\n",
      "Chi-Square testi ile feature selection yapılıyor...\n",
      "Chi-Square skorları hesaplanıyor (bu biraz zaman alabilir)...\n",
      "\n",
      "Tüm veri setine normalize ve feature selection uygulanıyor...\n",
      "Seçilen özellik sayısı: 100\n",
      "Seçilen özelliklerin ilk 10 indeksi: [  1   3   7 126 130 165 172 571 575 672]\n",
      "\n",
      "En yüksek Chi-Square skorlarına sahip 10 özellik:\n",
      "  Özellik 3: Chi2 = 90438.00\n",
      "  Özellik 1759: Chi2 = 2.49\n",
      "  Özellik 1741: Chi2 = 2.23\n",
      "  Özellik 1750: Chi2 = 2.13\n",
      "  Özellik 1745: Chi2 = 1.67\n",
      "  Özellik 1729: Chi2 = 155.49\n",
      "  Özellik 1777: Chi2 = 4.08\n",
      "  Özellik 1746: Chi2 = 1058.49\n",
      "  Özellik 1755: Chi2 = 0.08\n",
      "\n",
      "VERİ KULLANIMI:\n",
      "  - Normalizasyon: 150,000 örnek kullanıldı\n",
      "  - Feature selection: 150,000 örnek kullanıldı\n",
      "  - Seçilen özellik sayısı: 100\n",
      "  - Train set (seçilen özelliklerle): (796184, 100)\n",
      "  - Test set (seçilen özelliklerle): (199047, 100)\n"
     ]
    }
   ],
   "source": [
    "# Chi-Square için non-negative değerler gerekli (MinMax scaling)\n",
    "print(\"\\nChi-Square için veriler normalize ediliyor (0-1 arası)...\")\n",
    "scaler = MinMaxScaler()\n",
    "X_sample_dense = X_sample.toarray()\n",
    "X_sample_scaled = scaler.fit_transform(X_sample_dense)\n",
    "X_sample_scaled = csr_matrix(X_sample_scaled)  # Tekrar sparse'a çevir\n",
    "\n",
    "# Chi-Square: Kategorik özelliklerin target ile istatistiksel bağımsızlığını test eder\n",
    "print(\"\\nChi-Square testi ile feature selection yapılıyor...\")\n",
    "print(\"Chi-Square skorları hesaplanıyor (bu biraz zaman alabilir)...\")\n",
    "\n",
    "# En iyi 100 özelliği seç\n",
    "k_best = 100\n",
    "chi2_selector = SelectKBest(score_func=chi2, k=k_best)\n",
    "X_selected = chi2_selector.fit_transform(X_sample_scaled, y_sample)\n",
    "\n",
    "# Seçilen özelliklerin indekslerini al\n",
    "selected_indices = chi2_selector.get_support(indices=True)\n",
    "\n",
    "# Tüm train ve test setlerine uygula (önce normalize et)\n",
    "print(\"\\nTüm veri setine normalize ve feature selection uygulanıyor...\")\n",
    "X_train_dense = X_train_full.toarray()\n",
    "X_test_dense = X_test_full.toarray()\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train_dense)\n",
    "X_test_scaled = scaler.transform(X_test_dense)\n",
    "\n",
    "X_train_selected = csr_matrix(X_train_scaled[:, selected_indices])\n",
    "X_test_selected = csr_matrix(X_test_scaled[:, selected_indices])\n",
    "\n",
    "print(f\"Seçilen özellik sayısı: {len(selected_indices)}\")\n",
    "print(f\"Seçilen özelliklerin ilk 10 indeksi: {selected_indices[:10]}\")\n",
    "\n",
    "# Chi-Square skorlarını göster\n",
    "chi2_scores = chi2_selector.scores_\n",
    "valid_scores = chi2_scores[~np.isnan(chi2_scores)]\n",
    "if len(valid_scores) > 0:\n",
    "    top_10_indices = np.argsort(valid_scores)[-10:][::-1]\n",
    "    print(f\"\\nEn yüksek Chi-Square skorlarına sahip 10 özellik:\")\n",
    "    for idx in top_10_indices[:10]:\n",
    "        if not np.isnan(chi2_scores[idx]):\n",
    "            print(f\"  Özellik {idx}: Chi2 = {chi2_scores[idx]:.2f}\")\n",
    "\n",
    "print(f\"\\nVERİ KULLANIMI:\")\n",
    "print(f\"  - Normalizasyon: {X_sample.shape[0]:,} örnek kullanıldı\")\n",
    "print(f\"  - Feature selection: {X_sample.shape[0]:,} örnek kullanıldı\")\n",
    "print(f\"  - Seçilen özellik sayısı: {len(selected_indices)}\")\n",
    "print(f\"  - Train set (seçilen özelliklerle): {X_train_selected.shape}\")\n",
    "print(f\"  - Test set (seçilen özelliklerle): {X_test_selected.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model eğitimi başlıyor...\n",
      "Eğitim verisi: 796,184 örnek, 100 özellik\n",
      "Model eğitimi tamamlandı!\n",
      "\n",
      "En yüksek katsayıya sahip 10 özellik:\n",
      "  1. Özellik 3: Coef = 17.2317\n",
      "  2. Özellik 1: Coef = -1.0457\n",
      "  3. Özellik 1742: Coef = -0.9133\n",
      "  4. Özellik 1760: Coef = -0.9133\n",
      "  5. Özellik 1762: Coef = -0.5805\n",
      "  6. Özellik 1756: Coef = -0.5087\n",
      "  7. Özellik 1751: Coef = -0.3991\n",
      "  8. Özellik 1746: Coef = -0.3847\n",
      "  9. Özellik 1765: Coef = -0.1870\n",
      "  10. Özellik 1718: Coef = -0.1870\n",
      "\n",
      "VERİ KULLANIMI:\n",
      "  - Model eğitimi: 796,184 örnek kullanıldı\n",
      "  - Özellik sayısı: 100\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression: Doğrusal bir sınıflandırma modeli\n",
    "lr_model = LogisticRegression(\n",
    "    C=1.0,                    # Regularization parametresi\n",
    "    penalty='l2',             # L2 regularization (Ridge)\n",
    "    solver='lbfgs',           # Optimizasyon algoritması\n",
    "    max_iter=1000,           # Maksimum iterasyon\n",
    "    random_state=42,\n",
    "    class_weight='balanced',  # Dengesiz sınıflar için ağırlıklandırma\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Model eğitimi başlıyor...\")\n",
    "print(f\"Eğitim verisi: {X_train_selected.shape[0]:,} örnek, {X_train_selected.shape[1]} özellik\")\n",
    "lr_model.fit(X_train_selected, y_train_binary)\n",
    "print(\"Model eğitimi tamamlandı!\")\n",
    "\n",
    "# Katsayıları göster\n",
    "coefficients = lr_model.coef_[0]\n",
    "top_10_features = np.argsort(np.abs(coefficients))[-10:][::-1]\n",
    "print(f\"\\nEn yüksek katsayıya sahip 10 özellik:\")\n",
    "for i, idx in enumerate(top_10_features):\n",
    "    feat_idx = selected_indices[idx]\n",
    "    print(f\"  {i+1}. Özellik {feat_idx}: Coef = {coefficients[idx]:.4f}\")\n",
    "\n",
    "print(f\"\\nVERİ KULLANIMI:\")\n",
    "print(f\"  - Model eğitimi: {X_train_selected.shape[0]:,} örnek kullanıldı\")\n",
    "print(f\"  - Özellik sayısı: {X_train_selected.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tahmin edilen sınıf dağılımı:\n",
      "  Part 1 (0): 120009\n",
      "  Part 2 (1): 79038\n",
      "\n",
      "VERİ KULLANIMI:\n",
      "  - Test tahminleri: 199,047 örnek\n"
     ]
    }
   ],
   "source": [
    "# Test setine tahmin\n",
    "y_pred_proba = lr_model.predict_proba(X_test_selected)[:, 1]  # Part 2 olasılığı\n",
    "y_pred = lr_model.predict(X_test_selected)\n",
    "\n",
    "print(f\"Tahmin edilen sınıf dağılımı:\")\n",
    "print(f\"  Part 1 (0): {(y_pred == 0).sum()}\")\n",
    "print(f\"  Part 2 (1): {(y_pred == 1).sum()}\")\n",
    "\n",
    "print(f\"\\nVERİ KULLANIMI:\")\n",
    "print(f\"  - Test tahminleri: {X_test_selected.shape[0]:,} örnek\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AŞAMA 5: SUBMISSION DOSYASI OLUŞTURMA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Submission dosyasi kaydedildi: ismailcan_model2_submission.csv\n",
      "   Toplam tahmin sayısı: 199047\n",
      "\n",
      "======================================================================\n",
      "MODEL 2 TAMAMLANDI!\n",
      "======================================================================\n",
      "\n",
      "ÖZET:\n",
      "  - Feature Selection: Chi-Square Test (Top 100 features)\n",
      "  - Model: Logistic Regression (L2 regularization)\n",
      "  - Submission: ismailcan_model2_submission.csv\n",
      "\n",
      "VERİ KULLANIMI ÖZETİ:\n",
      "  - Toplam train verisi: 796,184 örnek\n",
      "  - Sampling (feature selection): 150,000 örnek\n",
      "  - Model eğitimi: 796,184 örnek\n",
      "  - Test tahminleri: 199,047 örnek\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test setindeki DR_NO'ları al\n",
    "submission_df = pd.DataFrame({\n",
    "    'DR_NO': df_test['DR_NO'].values if 'DR_NO' in df_test.columns else df_test.index.values,\n",
    "    'Part 1-2': y_pred\n",
    "})\n",
    "\n",
    "# Orijinal değerlere geri çevir\n",
    "submission_df['Part 1-2'] = submission_df['Part 1-2'].map({\n",
    "    0: -0.834220,\n",
    "    1: 1.198725\n",
    "})\n",
    "\n",
    "# Dosyayı kaydet\n",
    "submission_file = \"ismailcan_model2_submission.csv\"\n",
    "submission_df.to_csv(submission_file, index=False)\n",
    "print(f\"[OK] Submission dosyasi kaydedildi: {submission_file}\")\n",
    "print(f\"   Toplam tahmin sayısı: {len(submission_df)}\")\n",
    "\n",
    "# Model ve selector'ı kaydet\n",
    "joblib.dump(lr_model, \"ismailcan_model2_lr.pkl\")\n",
    "joblib.dump(chi2_selector, \"ismailcan_model2_selector.pkl\")\n",
    "joblib.dump(selected_indices, \"ismailcan_model2_selected_indices.pkl\")\n",
    "joblib.dump(scaler, \"ismailcan_model2_scaler.pkl\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL 2 TAMAMLANDI!\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nÖZET:\")\n",
    "print(f\"  - Feature Selection: Chi-Square Test (Top {k_best} features)\")\n",
    "print(f\"  - Model: Logistic Regression (L2 regularization)\")\n",
    "print(f\"  - Submission: {submission_file}\")\n",
    "print(\"\\nVERİ KULLANIMI ÖZETİ:\")\n",
    "print(f\"  - Toplam train verisi: {X_train_full.shape[0]:,} örnek\")\n",
    "print(f\"  - Sampling (feature selection): {X_sample.shape[0]:,} örnek\")\n",
    "print(f\"  - Model eğitimi: {X_train_selected.shape[0]:,} örnek\")\n",
    "print(f\"  - Test tahminleri: {X_test_selected.shape[0]:,} örnek\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
